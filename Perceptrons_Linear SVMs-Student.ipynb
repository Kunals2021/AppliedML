{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`By   : Dr. James G. Shanahan\n",
    "EMAIL: James.Shanahan AT Gmail.com`\n",
    "\n",
    "__For HW10, you will be expected to answer questions about your work in this notebook via Canvas (Modules->Module 10->HW10 Notebook and submission form). You may wish to reference this quiz while working through the assignment.__\n",
    "## Submission instructionsÂ¶\n",
    "Before completing this homework,\n",
    "1. please review this homework's submission form on Canvas available under the \"Modules\" menu option and briefly review this notebook end to end.\n",
    "2. To get you started we provide a template solution with missing code and prompts. Please complete the missing code, run the experiments and log your results.\n",
    "3. When you're sufficiently happy with your results, please begin the submission process on Canvas. Use the submission form for this homework available under \"Modules\" menu option. Please note that the submission form is available at the same place where you downloaded the homework from.\n",
    "4. You may wish to reference the submission form (Modules->Module 10->HW10 Notebook and submission form) while working through the tasks.\n",
    "\n",
    "Please complete all core assignment tasks (marked \"TASK\"). For your learnings, please complete the optional stretch assignment tasks (marked \"OPTIONAL\").\n",
    "\n",
    "The goals of this HW include the following:\n",
    "* Understanding the operation of a multiclass perceptron classifier.\n",
    "* Building a multiclass perceptron classifier.\n",
    "    * Applying regularization\n",
    "    * Evaluating performance metrics unique to a multiclass problem.\n",
    "* Tuning a multiclass perceptron for text classification.\n",
    "  \n",
    "You will submit the results of your work in this notebook using the **HW 10 Submission Form** assignment on Canvas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-17T21:05:11.015743Z",
     "start_time": "2018-11-17T21:05:11.012949Z"
    }
   },
   "source": [
    "## Prepare the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T22:29:33.648649Z",
     "start_time": "2018-11-21T22:29:30.646214Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.datasets import make_classification\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import reuters\n",
    "nltk.download('stopwords')\n",
    "nltk.download('reuters')\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from IPython.display import Image\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptrons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='./images/02_03.png', width=600) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='./images/02_04.png', width=600) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptrons in SKLearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data[:, (2, 3)]  # petal length, petal width\n",
    "y = (iris.target == 0).astype(np.int) #2-class problem Iris-Setosa versus not\n",
    "\n",
    "per_clf = Perceptron(random_state=42)\n",
    "per_clf.fit(X, y)\n",
    "\n",
    "#make a prediction for one example\n",
    "y_pred = per_clf.predict([[2, 0.5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "a = -per_clf.coef_[0][0] / per_clf.coef_[0][1]\n",
    "b = -per_clf.intercept_ / per_clf.coef_[0][1]\n",
    "\n",
    "axes = [0, 5, 0, 2]\n",
    "\n",
    "x0, x1 = np.meshgrid(\n",
    "        np.linspace(axes[0], axes[1], 500).reshape(-1, 1),\n",
    "        np.linspace(axes[2], axes[3], 200).reshape(-1, 1),\n",
    "    )\n",
    "X_new = np.c_[x0.ravel(), x1.ravel()]\n",
    "y_predict = per_clf.predict(X_new)\n",
    "zz = y_predict.reshape(x0.shape)\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(X[y==0, 0], X[y==0, 1], \"bs\", label=\"Not Iris-Setosa\")\n",
    "plt.plot(X[y==1, 0], X[y==1, 1], \"yo\", label=\"Iris-Setosa\")\n",
    "\n",
    "plt.plot([axes[0], axes[1]], [a * axes[0] + b, a * axes[1] + b], \"k-\", linewidth=3)\n",
    "from matplotlib.colors import ListedColormap\n",
    "custom_cmap = ListedColormap(['#9898ff', '#fafab0'])\n",
    "\n",
    "plt.contourf(x0, x1, zz, cmap=custom_cmap, linewidth=5)\n",
    "plt.xlabel(\"Petal length\", fontsize=14)\n",
    "plt.ylabel(\"Petal width\", fontsize=14)\n",
    "plt.legend(loc=\"lower right\", fontsize=14)\n",
    "plt.axis(axes)\n",
    "\n",
    "#plt.save_fig(\"perceptron_iris_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK: Multiclass Perceptron : variable importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the hyperplane coefficients barchart  with the pairwise visualization and complete the analysis provided below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data and build a perceptron classifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-18T01:46:34.927804Z",
     "start_time": "2018-11-18T01:46:34.908707Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "irisDataset = load_iris() \n",
    "\n",
    "X = irisDataset.data\n",
    "y = irisDataset.target\n",
    "\n",
    "#create a heldout dataset for final testing only\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.15, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.15, random_state=42)\n",
    "df = pd.DataFrame(X, columns=irisDataset.feature_names)\n",
    "df['IrisClass'] = y\n",
    "\n",
    "perceptron_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy=\"median\")), #Use the \"median\" to impute missing vlaues\n",
    "        ('std_scaler', StandardScaler()),\n",
    "        ('perceptron', Perceptron(random_state=42))\n",
    "    ])\n",
    "# Fit the train data to the pipeline\n",
    "# Predict for X-test\n",
    "#==================================================#\n",
    "#               Your code starts here              #\n",
    "#==================================================#\n",
    "perceptron_pipeline.fit...\n",
    "preds = ...      \n",
    "# TODO - change the following code\n",
    "# perceptron_pipeline.fit()\n",
    "# preds = \n",
    "#==================================================#\n",
    "#               Your code ends here                #\n",
    "#               Please don't add code below here   #\n",
    "#==================================================#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate visualizations (pairwise scatterplot and bar chart of the model coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-18T01:46:38.806120Z",
     "start_time": "2018-11-18T01:46:34.929719Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.pairplot(sns.load_dataset(\"iris\"), hue=\"species\", height=4);\n",
    "\n",
    "model = perceptron_pipeline.named_steps['perceptron']\n",
    "print(np.round(model.coef_,3))\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.bar(np.arange(model.coef_.shape[1]) - 0.2, model.coef_[0], color=\"red\", width=0.2, label=\"setosa\")\n",
    "plt.bar(np.arange(model.coef_.shape[1]) - 0.0, model.coef_[1], color=\"green\", width=0.2, label=\"versicolour\")\n",
    "plt.bar(np.arange(model.coef_.shape[1]) + 0.2, model.coef_[2], color=\"blue\", width=0.2, label=\"virginica\")\n",
    "plt.xticks(np.arange(model.coef_.shape[1]), df.columns[:4], rotation=0)\n",
    "plt.xlim([-1, model.coef_.shape[1]])\n",
    "plt.title(\"Multiclass Perceptron Model coefficients\")\n",
    "plt.legend(loc=\"lower right\");\n",
    "plt.grid()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill in the blanks to complete the analysis\n",
    "\n",
    "Use the results of the hyperplane cooefficient's barchart with the pairwise feature distributions to understand how the different features can be used to classify the different iris classes\n",
    "\n",
    "**Fill in the appropriate text:**\n",
    "\n",
    "Compare the hyperplane cooefficients barplot above with the pairwise feature distributions plotted previously.\n",
    "\n",
    "Looking at the barplot, one can see that **____________** has the least influence on defining a separating hyperplane for the versicolour class.  Looking at the the pairwise plot, this feature does not distinguish versicolour in combination with any other feature.\n",
    "\n",
    "Looking at the second column on the pairwise plot, setosa and versicolor classes are both impossible to distinguish based on **____________**; we can observe that 99% of the vertical lines that can be drawn, contain more than one class and hence wont be able to separate classes based on this feature.\n",
    "\n",
    "Both petal width and petal length are excellent features to consider since either one can separate 100% of **____________**.  In combination, they are able to separate close to 100% of the remaining classes too. **____________**  is the most influential factor in determining **____________** class. This is also clearly visible in the pairwise plot, as 99% of the vertical lines clearly indicate exactly one class.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Petal length and Virginica, or petal width and Versicolour were also acceptable options to the final pair of questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK: Multiclass  perceptron with regularization\n",
    "\n",
    "When youâre tired of running through the Iris or Breast Cancer orÂ  datasets (or Boston) for the umpteenth time, sklearn has a neat utility that lets you generate classification datasets (and regression datasets).\n",
    "\n",
    "Its use is pretty simple. A call to the function yields input attributes XÂ  and a target vector of the same length.Â "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 20) (100,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X, y = make_classification()\n",
    "print(X.shape, y.shape) # E.g., (100, 20) (100,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, you can customize the following:\n",
    "\n",
    "* number of linear combinations and repeated features to trip up your models,\n",
    "* or how many informative variables there are\n",
    "\n",
    "Note the total number of features comprise n_informative informative features, n_redundant redundant features, n_repeated duplicated features and n_features - n_informative-n_redundant-n_repeated useless features drawn at random.\n",
    "\n",
    "`X, y = make_classification(n_redundant=4, n_repeated=5, n_informative=10)`\n",
    "\n",
    "To understand the n_informative parameter, please read the sklearn manual pages - https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the SKLearn class `SGDClassifier` within the pipeline provided below, learn multiclass perceptron using gridsearch to evaluate:\n",
    "* L1, L2 and elasticnet regularization\n",
    "* alpha values $\\in [10, 1, 0.1, 0.01, 0.001)$\n",
    "\n",
    "References - https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html\n",
    "\n",
    "Report your accuracy score on your test data and the hyperparameters for your best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-18T01:46:41.557326Z",
     "start_time": "2018-11-18T01:46:38.809117Z"
    }
   },
   "outputs": [],
   "source": [
    "# The number of informative features. Each class is composed of a number\n",
    "# of gaussian clusters each located around the vertices of a hypercube\n",
    "# in a subspace of dimension ``n_informative``. For each cluster,\n",
    "# informative features are drawn independently from  N(0, 1) and then\n",
    "# randomly linearly combined within each cluster in order to add\n",
    "# covariance. The clusters are then placed on the vertices of the\n",
    "# hypercube.\n",
    "\n",
    "# generate classification dataset\n",
    "x, y = make_classification(1000, n_classes=3, n_informative=6, random_state=42)\n",
    "\n",
    "# generate splits for crossfold validation\n",
    "cv = KFold(3, random_state=42, shuffle=True)\n",
    "cv_idx = cv.split(x)\n",
    "\n",
    "\n",
    "# Create a pipeline, where the first step is scaling the features using StandardScaler()\n",
    "# and the second step is SGDClassifier() with loss='perceptron' and random_state=42\n",
    "#==================================================#\n",
    "#               Your code starts here              #\n",
    "#==================================================#\n",
    "pipeline = Pipeline(...)\n",
    "\n",
    "# TODO - change the following code\n",
    "# pipeline = Pipeline([\n",
    "#       ('std_scaler', ),\n",
    "#       ('perceptron', )\n",
    "# ])\n",
    "#==================================================#\n",
    "#               Your code ends here                #\n",
    "#               Please don't add code below here   #\n",
    "#==================================================#\n",
    "\n",
    "\n",
    "parameters = { \n",
    "    'perceptron__alpha': (10, 1, 0.1, 0.01, 0.001),\n",
    "    'perceptron__penalty': ('l1', 'l2', 'elasticnet'),\n",
    "}\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, parameters, cv=cv_idx, n_jobs=-1, verbose=1, )\n",
    "grid_search.fit(x,y)\n",
    "\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "    \n",
    "preds = grid_search.predict(x)\n",
    "accuracy = accuracy_score(preds, y)\n",
    "\n",
    "results = pd.DataFrame(columns=[\"Model\", \"Test Accuracy\"])\n",
    "results.loc[len(results)] = [\"Perceptron\", np.round(accuracy, 3)]\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate F1 score with micro and macro averaging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "## Equation  $F_1$ score\n",
    "\n",
    "$\n",
    "F_1 = \\cfrac{2}{\\cfrac{1}{\\text{precision}} + \\cfrac{1}{\\text{recall}}} = 2 \\times \\cfrac{\\text{precision}\\, \\times \\, \\text{recall}}{\\text{precision}\\, + \\, \\text{recall}} = \\cfrac{TP}{TP + \\cfrac{FN + FP}{2}}\n",
    "$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "So for our Reuters multiclass classification problem the labels are not binary, but are one-hot encoded. Fortunately, there are  options that work with this type of labeled  data for Precision:\n",
    "\n",
    "* precision_score(y_test, y_pred, average=None) will return the precision scores for each class, while\n",
    "* precision_score(y_test, y_pred, average='micro') will return the total ratio of tp/(tp + fp)\n",
    "* precision_score(y_test, y_pred, average='macro') will return macro average (class average = sum(precision)/numOfClasses). This option is much preferred which dealing with imbalanced data.\n",
    "\n",
    "The same is true for other performance measures such as F1.\n",
    "\n",
    "References - https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MultiLabelBinarizer.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run this code to generate targets and predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-18T01:46:41.596137Z",
     "start_time": "2018-11-18T01:46:41.561849Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "_, y1 = make_classification(n_samples=20, n_features=100, n_informative=30, n_classes=5, random_state=12)\n",
    "y2 = shuffle(y1, random_state=1)\n",
    "y3 = shuffle(y1, random_state=2)\n",
    "y4 = shuffle(y1, random_state=3)\n",
    "\n",
    "\n",
    "y_text = np.vstack((y1, y2, y3, y4)).T\n",
    "\n",
    "# One hot encode the target class variables\n",
    "mlb = MultiLabelBinarizer(classes=(0, 1, 2, 3, 4))\n",
    "y = mlb.fit_transform(y_text)\n",
    "\n",
    "# Use make_classification to create a cluster of 20 sample points\n",
    "# with a 100 features, 30 informative features, 5 classes\n",
    "# and random state =42\n",
    "#==================================================#\n",
    "#               Your code starts here              #\n",
    "#==================================================#\n",
    "_, y1 = make_classification...\n",
    "# TODO - change the following code\n",
    "# _, y1 = make_classification()\n",
    "#==================================================#\n",
    "#               Your code ends here                #\n",
    "#               Please don't add code below here   #\n",
    "#==================================================#\n",
    "\n",
    "\n",
    "y2 = shuffle(y1, random_state=1)\n",
    "y3 = shuffle(y1, random_state=2)\n",
    "y4 = shuffle(y1, random_state=3)\n",
    "y5 = shuffle(y1, random_state=4)\n",
    "\n",
    "#NOTE: Y target vector for 3 classes\n",
    "# note that each example can have one or MORE class labels\n",
    "y_preds_text = np.vstack((y1, y2, y3, y4, y5)).T     \n",
    "# One hot encode the target class variables\n",
    "mlb = MultiLabelBinarizer(classes=(0, 1, 2, 3, 4))\n",
    "y_preds = mlb.fit_transform(y_preds_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### These are the 20 multilabel targets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-18T01:46:41.602684Z",
     "start_time": "2018-11-18T01:46:41.598233Z"
    }
   },
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### These are the 20 predictions generated by our \"model\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-18T01:46:41.608774Z",
     "start_time": "2018-11-18T01:46:41.605105Z"
    }
   },
   "outputs": [],
   "source": [
    "print(y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK: Using the one-hot encoded targets and predictions data above (for 20 multi-label samples) calculate the F1 score using a micro and macro approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-18T01:46:41.620321Z",
     "start_time": "2018-11-18T01:46:41.611177Z"
    }
   },
   "outputs": [],
   "source": [
    "# Complete the following code to calculate the\n",
    "# F1 score with the micro and macro approach\n",
    "#==================================================#\n",
    "#               Your code starts here              #\n",
    "#==================================================#\n",
    "\n",
    "print(\"F1 Micro:\",round(f1_score(....),3))\n",
    "print(\"F1 Macro:\",round(f1_score(....),3))\n",
    "\n",
    "# TODO - change the following code\n",
    "# print(\"F1 Micro:\",round(f1_score(....),3))\n",
    "# print(\"F1 Macro:\",round(f1_score(....),3))\n",
    "#==================================================#\n",
    "#               Your code ends here                #\n",
    "#               Please don't add code below here   #\n",
    "#==================================================#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Optional Task] Reuters classification with different numbers of classes k\n",
    "\n",
    "\n",
    "**Reuters Description:**\n",
    "\n",
    "Reuters corpus is a collection of 21578 articles published on Reuters in 1987, collected and indexed into categories by Reuters ltd.\n",
    "\n",
    "The documents are Reuters newswire stories, and the categories are five different sets of content related categories.\n",
    "\n",
    "There are 7,769 training documents and 3,019 testing documents that have been hand classified by experts into 90 categories. Some documents have been assigned multtple categories.\n",
    "\n",
    "For example, the top three categories in the Reuters dataset are earn, acq and money-fx. The RAW corpus is distributed in a XML form and the documents are divided into several groups/splits.  However, a preprocessed version is available in NLTK. For more details see [here](http://www.nltk.org/howto/corpus.html)\n",
    "\n",
    "\n",
    "* The Reuters-21578 benchmark corpus, ApteMod version  id: reuters; size: 6378691; author: ; copyright: ; license: The copyright for the text of newswire articles and Reuters annotations in the Reuters-21578 collection resides with Reuters Ltd. Reuters Ltd. and Carnegie Group, Inc. have agreed to allow the free distribution of this data *for research purposes only*. If you publish results based on this data set, please acknowledge its use, refer to the data set by the name 'Reuters-21578, Distribution 1.0', and inform your readers of the current location of the data set.;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load all the data\n",
    "\n",
    "Using the code provided below, generate a series of experiments based on the Reuters dataset:\n",
    "\n",
    "At a minimum:\n",
    "* Compare the perceptron algorithm to logistic regression (\"log\" loss). \n",
    "* Experiment with unigrams and bigrams.\n",
    "* Experiment with at least two more hyperparameters.\n",
    "\n",
    "Keep a log of your results for each experiment in a table of results (pandas dataframe).  Your table of results should be a meaningful record or your work on this task, not a dump of grid search output for one experiment.  Please include:\n",
    "* Description of the model (e.g., Baseline Logistic Regression k=30, Perceptron k=50, etc.).\n",
    "* Identify key hyperparameters.\n",
    "* Precision, recall and F1 scores calculated using micro and macro approach.\n",
    "* Time to complete the experiment.\n",
    "* Hardware used.\n",
    "\n",
    "Think about how (and why) these changes affect your results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T22:29:44.767375Z",
     "start_time": "2018-11-21T22:29:42.463957Z"
    }
   },
   "outputs": [],
   "source": [
    "documents = reuters.fileids()\n",
    "test = [d for d in documents if d.startswith('test/')]\n",
    "train = [d for d in documents if d.startswith('training/')]\n",
    "\n",
    "cachedStopWords = nltk.download(\"stopwords\") #stopwords.words(\"english\")\n",
    "cachedStopWords = nltk.corpus.stopwords.words('english')\n",
    "np.random.seed(42)\n",
    "def loadReutersTrainTest():\n",
    "    documents = reuters.fileids()\n",
    "    train_docs_id = list(filter(lambda doc: doc.startswith(\"train\"), documents))\n",
    "    test_docs_id = list(filter(lambda doc: doc.startswith(\"test\"), documents))\n",
    "    #Input text\n",
    "    train_docs = [reuters.raw(doc_id) for doc_id in train_docs_id]\n",
    "    test_docs = [reuters.raw(doc_id) for doc_id in test_docs_id]\n",
    "    #Categories \n",
    "    # Complete the following code to get the categories\n",
    "    # of the train and the test set\n",
    "    #==================================================#\n",
    "    #               Your code starts here              #\n",
    "    #==================================================#\n",
    "    \n",
    "    train_target_names = [reuters.categories(...) for ... in ...]\n",
    "    test_target_names = [reuters.categories(...) for ... in ...]\n",
    "    \n",
    "    # TODO - change the following code\n",
    "    # train_target_names = [reuters.categories(...) for ... in ...]\n",
    "    # test_target_names = [reuters.categories(...) for ... in ...]\n",
    "    #==================================================#\n",
    "    #               Your code ends here                #\n",
    "    #               Please don't add code below here   #\n",
    "    #==================================================#\n",
    "    return(train_docs, test_docs, train_target_names, test_target_names)\n",
    "\n",
    "train_docs, test_docs, train_target_names, test_target_names = loadReutersTrainTest()\n",
    "\n",
    "print(\"Number of train docs is \", len(train_docs))\n",
    "print(\"Number of test docs is \", len(test_docs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The categories (classes) of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create counter to summarize\n",
    "categories = []\n",
    "file_count = []\n",
    "np.random.seed(42)\n",
    "# count each tag's number of documents\n",
    "for i in reuters.categories(reuters.fileids()):\n",
    "    \"\"\"print(\"$ There are {} documents included in topic \\\"{}\\\"\"\n",
    "          .format(len(reuters.fileids(i)), i))\"\"\"\n",
    "    file_count.append(len(reuters.fileids(i)))\n",
    "    categories.append(i)\n",
    "\n",
    "# create a dataframe out of the counts\n",
    "allCategories  = pd.DataFrame(\n",
    "    {'categories': categories, \"file_count\": file_count}) \\\n",
    "    .sort_values('file_count', ascending=False)\n",
    "allCategories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data using a number of classes k=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T22:29:46.281523Z",
     "start_time": "2018-11-21T22:29:46.277887Z"
    }
   },
   "outputs": [],
   "source": [
    "# determines number of categories\n",
    "k=20\n",
    "# Select documents that only contains top two labels with most documents\n",
    "category_filter =allCategories.iloc[0:k, 0].values.tolist()\n",
    "print(category_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T22:29:49.397750Z",
     "start_time": "2018-11-21T22:29:47.891040Z"
    }
   },
   "outputs": [],
   "source": [
    "#load examples for top K classes\n",
    "def loadReutersTrainTestTopFiltered(category_filter):\n",
    "    # select fileid with the category filter\n",
    "    np.random.seed(42)\n",
    "    documents = reuters.fileids()\n",
    "\n",
    "    doc_list = np.array(reuters.fileids(category_filter))\n",
    "    doc_list = doc_list[doc_list != 'training/3267']\n",
    "\n",
    "    train_docs_id = list(filter(lambda doc: doc.startswith(\"train\"), doc_list))\n",
    "    test_docs_id = list(filter(lambda doc: doc.startswith(\"test\"), doc_list))\n",
    "    #Input text\n",
    "    train_docs = [reuters.raw(doc_id) for doc_id in train_docs_id]\n",
    "    test_docs = [reuters.raw(doc_id) for doc_id in test_docs_id]\n",
    "    #Categories \n",
    "    train_target_names = [reuters.categories  (doc_id) for doc_id in train_docs_id]\n",
    "    test_target_names = [reuters.categories  (doc_id) for doc_id in test_docs_id]\n",
    "    #remove labels from each example that have not been selected\n",
    "    # ['earn', 'acq', 'money-fx', 'grain', 'crude', 'trade', 'interest', 'ship', 'wheat', 'corn']\n",
    "    # E.g., ['Japanese Anime',  'earn', 'acq']  --> ['earn', 'acq'] \n",
    "    transformedTags = []\n",
    "    for tags in train_target_names:\n",
    "        tagsTmp=[]\n",
    "        for tag in tags:\n",
    "            if tag in category_filter:\n",
    "                tagsTmp.append(tag)\n",
    "        transformedTags.append(tagsTmp)\n",
    "    train_target_namesK = transformedTags  \n",
    "    \n",
    "    transformedTags = []\n",
    "    for tags in test_target_names:\n",
    "        tagsTmp=[]\n",
    "        for tag in tags:\n",
    "            if tag in category_filter:\n",
    "                tagsTmp.append(tag)\n",
    "        transformedTags.append(tagsTmp)\n",
    "    test_target_namesK = transformedTags    \n",
    "   \n",
    "    return(train_docs, test_docs, train_target_namesK, test_target_namesK)\n",
    "\n",
    "train_docs, test_docs, train_target_names, test_target_names = loadReutersTrainTestTopFiltered(category_filter)\n",
    "print(\"Number of train docs is \", len(train_docs))\n",
    "print(\"Number of test docs is \", len(test_docs))\n",
    "mlb = MultiLabelBinarizer(classes=category_filter)\n",
    "Y_train = mlb.fit_transform(train_target_names)\n",
    "Y_test = mlb.fit_transform(test_target_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Defining the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a pipeline combining the text feature extractor CountVectorizer\n",
    "# using cachedStopWords as stop_words, TfidfTransformer() and \n",
    "# MultiOutputClassifier() with SGDClassifier() as a parameter and max_iter=50 as parameter within SGDClassifier()\n",
    "#==================================================#\n",
    "#               Your code starts here              #\n",
    "#==================================================#\n",
    "\n",
    "pipeline = Pipeline(...)\n",
    "\n",
    "\n",
    "# TODO - change the following code\n",
    "# pipeline = Pipeline([\n",
    "#     ('vect', ),\n",
    "#     ('tfidf', ), \n",
    "#     ('clf', )),])\n",
    "\n",
    "#==================================================#\n",
    "#               Your code ends here                #\n",
    "#               Please don't add code below here   #\n",
    "#==================================================#\n",
    "pipeline.named_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-18T01:55:28.281211Z",
     "start_time": "2018-11-18T01:46:45.490568Z"
    }
   },
   "outputs": [],
   "source": [
    "#Multi-labels per example evaluation\n",
    "def evaluate(test_labels, predictions):\n",
    "    precision = precision_score(test_labels, predictions, average='micro')\n",
    "    recall = recall_score(test_labels, predictions, average='micro')\n",
    "    f1 = f1_score(test_labels, predictions, average='micro')\n",
    "    print(\"Micro-average quality numbers\")\n",
    "    print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))\n",
    "\n",
    "    # Complete the following code to calculate the\n",
    "    # precision, recall and F1 score using the macro approach\n",
    "    #==================================================#\n",
    "    #               Your code starts here              #\n",
    "    #==================================================#\n",
    "    \n",
    "    precision = precision_score(...)\n",
    "    recall = recall_score(...)\n",
    "    f1 = f1_score(...)\n",
    "    \n",
    "    # TODO - change the following code\n",
    "    # precision = precision_score()\n",
    "    # recall = recall_score()\n",
    "    # f1 = f1_score()\n",
    "    #==================================================#\n",
    "    #               Your code ends here                #\n",
    "    #               Please don't add code below here   #\n",
    "    #==================================================#\n",
    "    print(\"Macro-average quality numbers\")\n",
    "    print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing GridSearch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# uncommenting more parameters will give better exploring power but will\n",
    "# increase processing time in a combinatorial way\n",
    "# Parameters of the estimators in the pipeline can be accessed using the <estimator>__<parameter> syntax:\n",
    "parameters = { #listed in the form of \"step__parameter\", e.g, clf__penalty\n",
    "    #'vect__max_df': (0.5, 0.75, 1.0),\n",
    "    #'vect__max_features': (None, 200,500),     \n",
    "    'vect__ngram_range': ((1, 1), (1, 2)),  # unigrams (single words) or bigrams (or sequence of words of length 2)\n",
    "    #'tfidf__use_idf': (True, False),\n",
    "    #'tfidf__norm': ('l1', 'l2'),\n",
    "    'clf__estimator__alpha': (0.001, 0.01, .1),        ## access parameters for the estimator inside\n",
    "    'clf__estimator__penalty': ('l1', 'l2', 'elasticnet'),  ## the MultioutputClassifier step by using\n",
    "    'clf__estimator__loss': ('perceptron', 'log')     ## step__MultioutputClassierParameter__EstimatorParameter\n",
    "}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # multiprocessing requires the fork to happen in a __main__ protected\n",
    "    # block\n",
    "\n",
    "    # find the best parameters for both the feature extraction and the\n",
    "    # classifier\n",
    "    # n_jobs=-1 means that the computation will be dispatched on all the CPUs of the computer.\n",
    "    #\n",
    "    # By default, the GridSearchCV uses a 3-fold cross-validation. However, if it \n",
    "    #            detects that a classifier is passed, rather than a regressor, it uses a stratified 3-fold.\n",
    "    #seeting shuffle=True\n",
    "    cv = KFold(n_splits=3, random_state=42, shuffle=True)\n",
    "    # added return_train_score=True\n",
    "    grid_search = GridSearchCV(pipeline, parameters, cv=cv, n_jobs=-2, verbose=1, scoring=\"f1_micro\", return_train_score=True)\n",
    "\n",
    "    print(\"Performing grid search...\")\n",
    "    print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "    print(\"parameters:\")\n",
    "    pprint(parameters)\n",
    "    t0 = time()\n",
    "    grid_search.fit(train_docs, Y_train)\n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "    print()\n",
    "    #print(\"grid_search.cv_results_\", grid_search.cv_results_)\n",
    "    #estimator : estimator object. This is assumed to implement the scikit-learn estimator interface.  \n",
    "    #            Either estimator needs to provide a score function, or scoring must be passed.\n",
    "    #Accuracy is the default for classification; feel free to change this to precision, recall, fbeta\n",
    "    print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "        \n",
    "    #Test on Heldlout test set\n",
    "    preds = grid_search.best_estimator_.predict(test_docs)\n",
    "    print(\"--------------------------------------------------------------------\")\n",
    "    evaluate(Y_test, preds)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mean_train_score\tand mean_test_score\n",
    "the gridsearch attribute of `cv_results_`  `mean_train_score` is calculated as the average of the training scores of each cross validation fold. Since in this case we are using `\"f1_micro\"`as as scoring metric. Each `mean_train_score` is the mean of the 3 (`n_splits=3`) `f1_micro scores`. The same logic applies for  `mean_test_score`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "results = pd.DataFrame(grid_search.cv_results_).loc[:, ['mean_train_score','mean_test_score','params','mean_fit_time','mean_score_time']].sort_values(by='mean_test_score', ascending=False)\n",
    "results.head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reuters Classification with SVM\n",
    "### Defining the pipeline for SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "# Define a pipeline combining the text feature extractor CountVectorizer\n",
    "# using cachedStopWords as stop_words, TfidfTransformer() and \n",
    "# MultiOutputClassifier() with SVC() as a parameter and max_iter=50 as parameter within SVC()\n",
    "#==================================================#\n",
    "#               Your code starts here              #\n",
    "#==================================================#\n",
    "\n",
    "pipeline = Pipeline(...)\n",
    "     \n",
    "# TODO - change the following code\n",
    "# pipeline = Pipeline([\n",
    "#     ('vect', ),\n",
    "#     ('tfidf', ), \n",
    "#     ('clf', )),])\n",
    "\n",
    "#==================================================#\n",
    "#               Your code ends here                #\n",
    "#               Please don't add code below here   #\n",
    "#==================================================#\n",
    "pipeline.named_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing gridsearch for SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.exceptions import ConvergenceWarning\n",
    "ConvergenceWarning('ignore')\n",
    "\n",
    "# uncommenting more parameters will give better exploring power but will\n",
    "# increase processing time in a combinatorial way\n",
    "# Parameters of the estimators in the pipeline can be accessed using the <estimator>__<parameter> syntax:\n",
    "parameters = { #listed in the form of \"step__parameter\", e.g, clf__penalty\n",
    "    'vect__ngram_range': ((1, 1), (1, 2)),  # unigrams (single words) or bigrams (or sequence of words of length 2)\n",
    "    #'tfidf__use_idf': (True, False),\n",
    "    #'tfidf__norm': ('l1', 'l2'),\n",
    "    'svm__estimator__C': (.1, 1, 10),        ## access parameters for the estimator inside\n",
    "    'svm__estimator__kernel': ('linear', 'poly'),  ## the MultioutputClassifier step by using\n",
    "    'svm__estimator__degree': (1,2,3)     ## step__MultioutputClassierParameter__EstimatorParameter\n",
    "}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # multiprocessing requires the fork to happen in a __main__ protected\n",
    "    # block\n",
    "\n",
    "    # find the best parameters for both the feature extraction and the\n",
    "    # classifier\n",
    "    # n_jobs=-1 means that the computation will be dispatched on all the CPUs of the computer.\n",
    "    #\n",
    "    # By default, the GridSearchCV uses a 3-fold cross-validation. However, if it \n",
    "    #            detects that a classifier is passed, rather than a regressor, it uses a stratified 3-fold.\n",
    "    \n",
    "    #setting shuffle=True\n",
    "    cv = KFold(n_splits=3, random_state=42, shuffle=True)\n",
    "    grid_search = GridSearchCV(pipeline, parameters, cv=cv, n_jobs=-2, verbose=1, scoring=\"f1_micro\", return_train_score=True)\n",
    "\n",
    "    print(\"Performing grid search...\")\n",
    "    print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "    print(\"parameters:\")\n",
    "    pprint(parameters)\n",
    "    t0 = time()\n",
    "    grid_search.fit(train_docs, Y_train)\n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "    print()\n",
    "    #print(\"grid_search.cv_results_\", grid_search.cv_results_)\n",
    "    #estimator : estimator object. This is assumed to implement the scikit-learn estimator interface.  \n",
    "    #            Either estimator needs to provide a score function, or scoring must be passed.\n",
    "    #Accuracy is the default for classification; feel free to change this to precision, recall, fbeta\n",
    "    print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    # Complete the code below to get the parameters of your best model based on gridsearch\n",
    "    #==================================================#\n",
    "    #               Your code starts here              #\n",
    "    #==================================================#\n",
    "    best_parameters = ...\n",
    "    \n",
    "    # TODO - change the following code\n",
    "    # best_parameters = \n",
    "    #==================================================#\n",
    "    #               Your code ends here                #\n",
    "    #               Please don't add code below here   #\n",
    "    #==================================================#\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "        \n",
    "    #Test on Heldlout test set\n",
    "    preds = grid_search.best_estimator_.predict(test_docs)\n",
    "    print(\"--------------------------------------------------------------------\")\n",
    "    evaluate(Y_test, preds)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "results = pd.DataFrame(grid_search.cv_results_).loc[:, ['mean_train_score','mean_test_score','params','mean_fit_time','mean_score_time']].sort_values(by='mean_test_score', ascending=False)\n",
    "results.head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# [Optional Task] Multiclass perceptron: classification+training\n",
    "\n",
    "Like most other techniques for training linear classifiers, the perceptron generalizes naturally to multiclass classification. Here, the input ${\\displaystyle x}$  and the output ${\\displaystyle y}$  are drawn from arbitrary sets. A feature representation function ${\\displaystyle f(x,y)}$  maps each possible input/output pair to a finite-dimensional real-valued feature vector. As before, the feature vector is multiplied by a weight vector ${\\displaystyle w}$, but now the resulting score is used to choose among many possible outputs:\n",
    "\n",
    "$${\\displaystyle {\\hat {y}}=\\operatorname {argmax} _{y}f(x,y)\\cdot w.} $$\n",
    "\n",
    "\n",
    "\n",
    "Learning again iterates over the examples, predicting an output for each, leaving the weights unchanged when the predicted output matches the target, and changing them when it does not. \n",
    "\n",
    "Given that the predicted class ${\\hat{y}}$ is different to that actual class $y$:\n",
    "\n",
    "\n",
    "$${\\displaystyle {\\hat {y}}=\\operatorname {argmax} _{y}f(x,y)\\cdot w.} $$\n",
    "\n",
    "the update becomes for each $w_{i,j}$:\n",
    "\n",
    "\n",
    "\n",
    "$\n",
    "\\begin{split}\n",
    "\\operatorname{update}(\\hat{y},y) =\n",
    "\\begin{cases}\n",
    "y_j = y& {w_{i,j}}^{(\\text{next step})} = w_{i,j} + \\eta  x_i\\\\\n",
    "{y}_k = \\hat{y}  & {w_{i,k}}^{(\\text{next step})} = w_{i,k} - \\eta  x_i\n",
    "\\end{cases} & \\quad\\quad\n",
    "\\end{split}\n",
    "$\n",
    "\n",
    "The above gradient update step for the multiclass perceptron is as follows:\n",
    "* for every wrong prediction, penalize(reduce) the weights (and perpendicular distance) that got predicted wrongly and \n",
    "* increase the weights of the class that was the target, that we failed to predict correctly.\n",
    "\n",
    "\n",
    "This multiclass feedback formulation reduces to the original perceptron when ${\\displaystyle x}$  is a real-valued vector, ${\\displaystyle y}$ is chosen from ${\\displaystyle \\{0,1\\}} $, and ${\\displaystyle f(x,y)=yx} $.\n",
    "\n",
    "** Perceptron learning rule (weight update) for binary classifier**\n",
    "\n",
    "$\n",
    "{w_{i,j}}^{(\\text{next step})} = w_{i,j} + \\eta (y_j - \\hat{y}_j) x_i\n",
    "$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Optional Task] Complete the following code to build a Multiclass Perceptron algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-18T01:55:28.292099Z",
     "start_time": "2018-11-18T01:55:28.283256Z"
    }
   },
   "outputs": [],
   "source": [
    "class HomeGrownPerceptron(object):\n",
    "    \"\"\"Perceptron classifier.\n",
    "\n",
    "    Parameters\n",
    "    ------------\n",
    "    eta : float\n",
    "      Learning rate (between 0.0 and 1.0)\n",
    "    n_iter : int\n",
    "      Passes over the training dataset.\n",
    "    random_state : int\n",
    "      Random number generator seed for random weight\n",
    "      initialization.\n",
    "\n",
    "    Attributes\n",
    "    -----------\n",
    "    w_ : 1d-array\n",
    "      Weights after fitting.\n",
    "    errors_ : list\n",
    "      Number of misclassifications (updates) in each epoch.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, eta=0.01, n_iter=50, random_state=1):\n",
    "        self.eta = eta\n",
    "        self.n_iter = n_iter\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit training data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like}, shape = [n_samples, n_features]\n",
    "          Training vectors, where n_samples is the number of samples and\n",
    "          n_features is the number of features.\n",
    "        y : array-like, shape = [n_samples]\n",
    "          Target values.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "\n",
    "        \"\"\"\n",
    "        rgen = np.random.RandomState(self.random_state)\n",
    "        self.w_ = rgen.normal(loc=0.0, scale=0.01, size=1 + X.shape[1])\n",
    "        self.errors_ = []\n",
    "\n",
    "        for _ in range(self.n_iter):\n",
    "            errors = 0\n",
    "            for xi, target in zip(X, y):\n",
    "                update = self.eta * (target - self.predict(xi))\n",
    "                self.w_[1:] += update * xi\n",
    "                self.w_[0] += update\n",
    "                errors += int(update != 0.0)\n",
    "            self.errors_.append(errors)\n",
    "        return self\n",
    "\n",
    "    def net_input(self, X):\n",
    "        \"\"\"Calculate net input\"\"\"\n",
    "        return np.dot(X, self.w_[1:]) + self.w_[0]\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Return class label after unit step\"\"\"\n",
    "        return np.where(self.net_input(X) >= 0.0, 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-18T01:55:28.304411Z",
     "start_time": "2018-11-18T01:55:28.293928Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class MulticlassHomeGrownPerceptron(HomeGrownPerceptron):\n",
    "    \"\"\" Multiclass HomeGrown Perceptron classifier.\"\"\"\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit training data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like}, shape = [n_samples, n_features]\n",
    "          Training vectors, where n_samples is the number of samples and\n",
    "          n_features is the number of features.\n",
    "        y : array-like, shape = [n_samples]\n",
    "          Target values.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "\n",
    "        \"\"\"\n",
    "        n_classes = np.unique(y).size\n",
    "        rgen = np.random.RandomState(self.random_state)\n",
    "        self.w_ = rgen.normal(loc=0.0, scale=0.01, size=(n_classes, 1 + X.shape[1]))\n",
    "        self.errors_ = []\n",
    "\n",
    "        for _ in range(self.n_iter):\n",
    "            errors = 0\n",
    "            for xi, target in zip(X, y):\n",
    "                predicted = self.predict(xi)\n",
    "                if target != predicted:  #Mistake\n",
    "                    # Complete the following code to \n",
    "                    # Reduce the score of the incorrectly predicted class\n",
    "                    #==================================================#\n",
    "                    #               Your code starts here              #\n",
    "                    #==================================================#\n",
    "                    \n",
    "                    ...\n",
    "                    \n",
    "                    # TODO - change the following code\n",
    "                    # self.w_[predicted,1:] = \n",
    "                    # self.w_[predicted,0] = \n",
    "                    #==================================================#\n",
    "                    #               Your code ends here                #\n",
    "                    #               Please don't add code below here   #\n",
    "                    #==================================================#\n",
    "                    #increase the score of the true class\n",
    "                    self.w_[target,1:] += self.eta * xi\n",
    "                    self.w_[target,0] += self.eta\n",
    "                    errors += 1\n",
    "            self.errors_.append(errors)\n",
    "        return self\n",
    "\n",
    "    def net_input(self, X):\n",
    "        \"\"\"Calculate net input\"\"\"\n",
    "        return np.dot(X, self.w_[:,1:].T) + self.w_[:,0].T\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Return class label after unit step\"\"\"\n",
    "        if X.ndim == 1:\n",
    "            return np.argmax(self.net_input(X))\n",
    "        else:\n",
    "            return np.argmax(self.net_input(X), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-18T01:55:28.313237Z",
     "start_time": "2018-11-18T01:55:28.306989Z"
    }
   },
   "outputs": [],
   "source": [
    "wine = load_wine()\n",
    "data = wine.data\n",
    "targets = wine.target\n",
    "target_names = wine.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data. Confirm split and check class distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-18T01:55:28.323419Z",
     "start_time": "2018-11-18T01:55:28.315547Z"
    }
   },
   "outputs": [],
   "source": [
    "Xtrain, Xtest, ytrain, ytest = train_test_split(data, targets, test_size=.2, shuffle=True, random_state=42)\n",
    "\n",
    "print('Train: {}   {}'.format(Xtrain.shape, ytrain.shape))\n",
    "print('Test: {}   {}'.format(Xtest.shape, ytest.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-18T01:55:28.332874Z",
     "start_time": "2018-11-18T01:55:28.325792Z"
    }
   },
   "outputs": [],
   "source": [
    "vals = np.unique(ytrain)\n",
    "print('Train data')\n",
    "for v in vals:\n",
    "    print('{}: {}'.format(target_names[v], np.sum(ytrain == v)))\n",
    "    \n",
    "print('\\nTest data')\n",
    "for v in vals:\n",
    "    print('{}: {}'.format(target_names[v], np.sum(ytest == v)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit data\n",
    "Fit homegrown model and generate predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-18T01:55:28.450499Z",
     "start_time": "2018-11-18T01:55:28.340344Z"
    }
   },
   "outputs": [],
   "source": [
    "mcp = MulticlassHomeGrownPerceptron()\n",
    "# fit the multiclass homegrown perceptron to the training data\n",
    "# Predict classes for training data and test data\n",
    "#==================================================#\n",
    "#               Your code starts here              #\n",
    "#==================================================#\n",
    "mcp.fit(Xtrain, ytrain)\n",
    "ytrain_preds = ...\n",
    "ytest_preds = ...\n",
    "# TODO - change the following code\n",
    "# mcp.fit()\n",
    "# ytrain_preds = \n",
    "# ytest_preds = \n",
    "#==================================================#\n",
    "#               Your code ends here                #\n",
    "#               Please don't add code below here   #\n",
    "#==================================================#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "Calculate metrics using micro and macro average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-18T01:55:28.480876Z",
     "start_time": "2018-11-18T01:55:28.456247Z"
    }
   },
   "outputs": [],
   "source": [
    "y = {'Train': [ytrain, ytrain_preds], 'Test': [ytest, ytest_preds]}\n",
    "results = pd.DataFrame(columns = ['Model', 'Accuracy', 'Precision Micro ', 'Precision Macro'])\n",
    "for k in y.keys():\n",
    "    results.loc[len(results)] = ['Homegrown Multiclass Perceptron ({})'.format(k),\n",
    "               round(accuracy_score(y[k][0], y[k][1]),5), \n",
    "               round(precision_score(y[k][0], y[k][1], average='micro'),5),\n",
    "               round(precision_score(y[k][0], y[k][1], average='macro'),3)]  \n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines \n",
    "\n",
    "Support vector machines (SVMs) are a set of supervised learning methods used for classification, regression and outlier detection (not covered in this course). The advantages of support vector machines are: Effective in high dimensional spaces. Still effective in cases where number of dimensions is greater than the number of samples. For classification tasks, given a set of training examples, each marked as belonging to one or the other of two categories, an SVM training algorithm builds a model, a separating hyperplane, that assigns new examples to one category or the other, making it a non-probabilistic binary linear classifier (although methods such as Platt scaling exist to use SVM in a probabilistic classification setting). The perpendicular distance from a data point multiplied by its class (+1 or -1), a quantity known as the margin, once again, is key to learning a binary classifier.  SVM classifiers, logistic regression models, and perceptrons used the same raw ingredients for training and end up sometimes with very similar models. We touch on these similarities and differences here. \n",
    "\n",
    "SVMs can be easily generalized to solve a variety of machine learning problems such as :\n",
    "* multi-class problems\n",
    "* regression\n",
    "* semi-supervised learning (have both label and unlabeled examples in the training set) [not covered in this course] \n",
    "* outlier detection \n",
    "\n",
    "\n",
    "In this section of the notebook, we are doing a background review of your understanding of SVM. The first part is plotting different SVM kernels and see how that changes the classification. \n",
    "The second part aims to show the effects of margins on SVM classification.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot different Kernels\n",
    "\n",
    "\n",
    "In this module, we have introduced linear SVMs for classification and shown strong parallels between them and the perceptron. There are many extensions to SVMs that we will introduce in a later module. One extension revolves around implicit feature generation using kernels.  A kernel is a function used in SVM  that provides shortcuts to avoid complex calculations. The amazing thing about kernel is that we can go to higher dimensions and perform smooth calculations with the help of it. In this section, we get a visual insight of the nonlinear decision boundaries that can be formed using these (non-linear) kernel extensions to SVMs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets, svm\n",
    "import matplotlib.patches as mpatches\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X = X[y != 0, :2]\n",
    "y = y[y != 0]\n",
    "\n",
    "n_sample = len(X)\n",
    "colors = ['green','blue']\n",
    "groups=[\"Class 1 points\", \"Class 2 points\"]\n",
    "np.random.seed(0)\n",
    "order = np.random.permutation(n_sample)\n",
    "X = X[order]\n",
    "y = y[order].astype(np.float)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.7, random_state=42)\n",
    "\n",
    "# fit the model\n",
    "for fig_num, kernel in enumerate(('linear', 'rbf', 'poly')):\n",
    "    # create an svm model for each of the kernels with gamma=10\n",
    "    # fit the train data and calculate accuracy for train & test data\n",
    "    #==================================================#\n",
    "    #               Your code starts here              #\n",
    "    #==================================================#\n",
    "    \n",
    "    ...\n",
    "    \n",
    "    # TODO - change the following code\n",
    "    # clf = svm.SVC()\n",
    "    # clf.fit()\n",
    "    # train_acc= \n",
    "    # test_acc= \n",
    "    #==================================================#\n",
    "    #               Your code ends here                #\n",
    "    #               Please don't add code below here   #\n",
    "    #==================================================#\n",
    "    print (kernel , \" kernel => train accuracy:\", np.round(train_acc,3), \"test accuracy: \", np.round(test_acc,3))\n",
    "    print( \"number of support vectors\",np.sum(clf.n_support_))\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.figure(fig_num)\n",
    "    plt.clf()\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, zorder=10, s=20,cmap=matplotlib.colors.ListedColormap(colors))\n",
    "    plt.axis('tight')\n",
    "    x_min = X[:, 0].min()\n",
    "    x_max = X[:, 0].max()\n",
    "    y_min = X[:, 1].min()\n",
    "    y_max = X[:, 1].max()\n",
    "\n",
    "    XX, YY = np.mgrid[x_min:x_max:200j, y_min:y_max:200j]\n",
    "    Z = clf.decision_function(np.c_[XX.ravel(), YY.ravel()])\n",
    "\n",
    "    # Put the result into a color plot\n",
    "    Z = Z.reshape(XX.shape)\n",
    "    #plt.pcolormesh(XX, YY, Z > 0, cmap=plt.cm.Paired)\n",
    "    plt.contour(XX, YY, Z, colors=['k', 'k', 'k'],\n",
    "                linestyles=['--', '-', '--'], levels=[-.5, 0, .5])\n",
    "    plt.scatter(clf.support_vectors_[:,0],clf.support_vectors_[:,1], c='r', s=30, label= \"support vectors\")\n",
    "    red_patch = mpatches.Patch(color='red', label='Support Vectors')\n",
    "    blue_patch = mpatches.Patch(color='blue', label='Class 1 points')\n",
    "    green_patch = mpatches.Patch(color='green', label='Class 2 points')\n",
    "    plt.legend(handles=[red_patch, blue_patch,green_patch])\n",
    "    plt.title(kernel)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Soft margin vs. harder margins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X = X[y != 2, :2]\n",
    "y = y[y != 2]\n",
    "\n",
    "n_sample = len(X)\n",
    "\n",
    "np.random.seed(0)\n",
    "order = np.random.permutation(n_sample)\n",
    "X = X[order]\n",
    "y = y[order].astype(np.float)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "svm_clf1 = LinearSVC(C=1, loss=\"hinge\", random_state=42)    # Soft SVM\n",
    "svm_clf2 = LinearSVC(C=100, loss=\"hinge\", random_state=42)  #Harder SVM\n",
    "# build the two pipelines for the for the soft svm and the harder svm\n",
    "# the first step is sclaing the data for both pipelines\n",
    "#==================================================#\n",
    "#               Your code starts here              #\n",
    "#==================================================#\n",
    "\n",
    "scaled_svm_clf1 = Pipeline(...)\n",
    "\n",
    "# TODO - change the following code\n",
    "# scaled_svm_clf1 = Pipeline([\n",
    "#         (\"scaler\", ),\n",
    "#         (\"linear_svc1\", ),\n",
    "# ])\n",
    "# scaled_svm_clf2 = Pipeline([\n",
    "#         (\"scaler\", scaler),\n",
    "#        (\"linear_svc2\", ),\n",
    "# ]) \n",
    "#==================================================#\n",
    "#               Your code ends here                #\n",
    "#               Please don't add code below here   #\n",
    "#==================================================#\n",
    "\n",
    "\n",
    "scaled_svm_clf1.fit(X_train, y_train)\n",
    "scaled_svm_clf2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to unscaled parameters\n",
    "b1 = svm_clf1.decision_function([-scaler.mean_ / scaler.scale_])\n",
    "b2 = svm_clf2.decision_function([-scaler.mean_ / scaler.scale_])\n",
    "w1 = svm_clf1.coef_[0] / scaler.scale_\n",
    "w2 = svm_clf2.coef_[0] / scaler.scale_\n",
    "svm_clf1.intercept_ = np.array([b1])\n",
    "svm_clf2.intercept_ = np.array([b2])\n",
    "svm_clf1.coef_ = np.array([w1])\n",
    "svm_clf2.coef_ = np.array([w2])\n",
    "\n",
    "# Find support vectors (LinearSVC does not do this automatically)\n",
    "t = y * 2 - 1\n",
    "support_vectors_idx1 = (t * (X.dot(w1) + b1) < 1).ravel()\n",
    "support_vectors_idx2 = (t * (X.dot(w2) + b2) < 1).ravel()\n",
    "svm_clf1.support_vectors_ = X[support_vectors_idx1]\n",
    "svm_clf2.support_vectors_ = X[support_vectors_idx2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_svc_decision_boundary(svm_clf, xmin, xmax):\n",
    "    w = svm_clf.coef_[0]\n",
    "    b = svm_clf.intercept_[0]\n",
    "\n",
    "    # At the decision boundary, w0*x0 + w1*x1 + b = 0\n",
    "    # => x1 = -w0/w1 * x0 - b/w1\n",
    "    x0 = np.linspace(xmin, xmax, 200)\n",
    "    decision_boundary = -w[0]/w[1] * x0 - b/w[1]\n",
    "    # Complete the code below to calculate the margin\n",
    "    # and gutter_up and gutter_down for the decision boundary\n",
    "    #==================================================#\n",
    "    #               Your code starts here              #\n",
    "    #==================================================#\n",
    "    \n",
    "    ...\n",
    "    \n",
    "    # TODO - change the following code\n",
    "    # margin = \n",
    "    # gutter_up = \n",
    "    # gutter_down = \n",
    "    #==================================================#\n",
    "    #               Your code ends here                #\n",
    "    #               Please don't add code below here   #\n",
    "    #==================================================#\n",
    "    \n",
    "    \n",
    "    # NOTE: we have two support vectors\n",
    "    svs = svm_clf.support_vectors_\n",
    "    plt.scatter(svs[:, 0], svs[:, 1], s=180, facecolors='#FFAAAA')\n",
    "    plt.plot(x0, decision_boundary, \"k-\", linewidth=2)\n",
    "    plt.plot(x0, gutter_up, \"k--\", linewidth=2)\n",
    "    plt.plot(x0, gutter_down, \"k--\", linewidth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc1= scaled_svm_clf1.score(X_train,y_train)\n",
    "test_acc1= scaled_svm_clf1.score (X_test,y_test)\n",
    "train_acc2= scaled_svm_clf2.score(X_train,y_train)\n",
    "test_acc2= scaled_svm_clf2.score (X_test,y_test)\n",
    "print (\" soft margins C=1 => train accuracy:\", train_acc1, \"test accuracy: \", test_acc1)\n",
    "print (\" harder margins C=100 => train accuracy:\", train_acc2, \"test accuracy: \", test_acc2)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.subplot(121)\n",
    "plt.plot(X[:, 0][y==1], X[:, 1][y==1], \"g^\", label=\"Iris-Virginica\")\n",
    "plt.plot(X[:, 0][y==0], X[:, 1][y==0], \"bo\", label=\"Iris-Versicolor\")\n",
    "plot_svc_decision_boundary(svm_clf1, 2, 8)\n",
    "plt.xlabel(\"Petal length\", fontsize=14)\n",
    "plt.ylabel(\"Petal width\", fontsize=14)\n",
    "plt.legend(loc=\"upper left\", fontsize=14)\n",
    "plt.title(\"$C = {}$\".format(svm_clf1.C), fontsize=16)\n",
    "plt.axis([4,7, 1, 5])\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(X[:, 0][y==1], X[:, 1][y==1], \"g^\")\n",
    "plt.plot(X[:, 0][y==0], X[:, 1][y==0], \"bo\")\n",
    "plot_svc_decision_boundary(svm_clf2, 2, 8)\n",
    "plt.xlabel(\"Petal length\", fontsize=14)\n",
    "plt.title(\"$C = {}$\".format(svm_clf2.C), fontsize=16)\n",
    "plt.axis([4, 7, 1.5, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "282.391px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-autonumbering": true,
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
